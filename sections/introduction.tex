%!TEX root=../icsme2016-mrstudyr.tex

\section{Introduction}

% Determining the quality of a test suite illustrates how stringently the given program was tested.

% Introduce software testing

Software developers may introduce errors into a program's source code that could result in a human
fatality~\cite{vicente2003programming}. Running a set of tests, frequently called a test suite, often aids in detecting
the faults that cause a program to function incorrectly~\cite{Kapfhammer2010}. Yet, simply testing a program is not
sufficient. In order for testing to establish a confidence in the correctness of the program under test, the test suite
needs to be of a high level of quality~\cite{Kapfhammer2004}.

% Introduce mutation testing and its benefits

Mutation testing is a widely-recognized technique for assessing the quality of a test suite~\cite{gopinath2015mutation}.
While there are many potential faults for a program, mutation testing focuses on those that are ``close'' to the correct
version, with the expectation that they will be representative of all faults~\cite{jia2011analysis}. Of the methods for
evaluating test quality, mutation testing is widely considered the strongest test criterion in terms of its capability
to necessitate the creation of tests that find many faults~\cite{ammann2008introduction}.

% Talk about the limitations of mutation testing

Although mutation testing effectively requires tests to detect faults, it has major drawbacks in its computational cost
and the amount of necessary human interaction, often making it impractical to use~\cite{gopinath2015mutation, Just2011a,
gopinath2015empirical}.  A major computational cost of mutation testing comes from executing each test case in a test
suite for the many generated mutants~\cite{Just2012b, offutt1993experimental}. Executing a small, representative set of
mutants against the test suite has previously been proposed as a technique to reduce the cost of mutation
testing~\cite{jia2011analysis, wong1995reducing, offutt1993experimental}; this reduction strategy is categorized by
Offutt and Untch as a ``do fewer'' approach~\cite{offutt2001mutation}.

% Introduce the technique call random mutant sampling

% Due to its simplicity, mutant sampling is considered to be the most cost-effective reduction technique by avoiding
% implementation complexities~\cite{gopinath2015mutation}.  Although it is simple to implement, mutant sampling has still
% been empirically shown to outperform other techniques~\cite{zhang2010operator}.

% TODO: Before the paragraph used operator-based selection in a way that seemed to be incorrect; please check this new
% content. I think that only zhang2013 actually explains this point (and they call it something slightly different).

There are several mutant reduction techniques in the ``do fewer'' category, with mutant sampling being a simple method
that randomly selects a subset of all mutants~\cite{wong1995reducing}. In addition to being conceptually
simple~\cite{gopinath2015mutation}, mutant sampling has been experimentally shown to outperform other more sophisticated
methods~\cite{zhang2010operator}.  Two sub-techniques within mutant sampling are called uniform random sampling and
sampling over operators~\cite{gopinath2015mutation, gopinath2015empirical, Zhang2013}.  For both of these sub-techniques, a
threshold for the maximum percentage of selected mutants is set to $x$, which is then either applied to the entire set
of mutants or to each set of mutants produced by an operator~\cite{gopinath2015mutation, gopinath2015empirical,
Zhang2013}.

% GMK NOTE: Cut this sentence as it is not precisely the point that we want to main in this paper

% While this way of evaluating reduction techniques is accurate, it is both expensive to implement and perform due to the
% number of times mutation testing needs to be executed.

% GMK NOTE: Here is the source code analysis of the PIT tool using the cloc program (see script in the bin/ directory)

% ./cloc-git https://github.com/hcoles/pitest
% Cloning into 'temp-linecount-repo'...
% remote: Counting objects: 1240, done.
% remote: Compressing objects: 100% (931/931), done.
% remote: Total 1240 (delta 297), reused 557 (delta 122), pack-reused 0
% Receiving objects: 100% (1240/1240), 583.98 KiB | 0 bytes/s, done.
% Resolving deltas: 100% (297/297), done.
% Checking connectivity... done.
% ('temp-linecount-repo' will be deleted automatically)

     % 843 text files.
     % 833 unique files.
     %  63 files ignored.

% http://cloc.sourceforge.net v 1.60  T=1.79 s (456.9 files/s, 36462.9 lines/s)
% -------------------------------------------------------------------------------
% Language                     files          blank        comment           code
% -------------------------------------------------------------------------------
% Java                           780          11126           8087          43030
% Maven                           29            136             23           2287
% XML                              3             33             69            377
% CSS                              1              4              0             36
% Groovy                           2             10              0             32
% YAML                             1              4              1             21
% Bourne Shell                     2              0              0              2
% -------------------------------------------------------------------------------
% SUM:                           818          11313           8180          45785
% -------------------------------------------------------------------------------

% Discuss the challenges associated with these types of analyses, drawing on the code example of PIT

Prior work has found the smallest value of $x$ that still produces a representative set of
mutants~\cite{jia2011analysis, mathur1994empirical}. Yet, these efforts normally required the experimenters to integrate
a reduction technique into an existing mutation testing system before performing a mutation testing
experiment~\cite{demillo1988extended, king1991fortran}. Since mutation testing tools are often complex --- according to
the Count Lines of Code ({\tt cloc}) tool the PIT mutation testing system contains over 43,000 lines of non-commented
Java code and thousands of lines of build and configuration files --- this approach to studying mutant reduction methods
has a high upfront cost. That is, researchers in this field must grasp the complexities of a mutation testing tool
before they can experimentally evaluate new techniques for mutant reduction.

% Retrospectively studying the data collected from a single execution of mutation testing is superior because of its
% minimal upfront costs and the implementation complexities of a target environment are obviated.

% Retrospective analysis is more cost-effective than applying a mutant reduction technique and then evaluating it.  This
% is the case because the expense of mutation testing in retrospective analysis is incurred only once, rather than for
% every reduction technique. Analysing the effectiveness of an approach retrospectively is possible because the necessary
% data can be collected from a prior analysis of all mutants.  This paper introduces \mr, the first and only tool that
% analyses reduction techniques retrospectively.

% GMK NOTE: Even this sentence is not really needed!

% This paper advocates a new way to empirically study mutant reduction methods.

% Introduce the idea of retrospectively studying a mutant reduction method

As a means for obviating the need for researchers to grasp a complex mutation testing system, this paper advances the
idea of retrospectively studying mutant reducers.  After using a tool like PIT to collect data about which operators ran
and what mutants they produced, a retrospective analysis applies strategies like uniform random sampling to the mutant
data, thereby quickly facilitating an understanding of a reduction method's trade-offs. Only after researchers
comprehend how the mutant reducers work in the intended domain must they then grapple with the complexities of the
chosen tool.

% TODO: Is there a place in the paper where we support this claim of the tool being well-documented?

% Okay, now introduce the tool and explain why it is novel

Since retrospective analysis still requires tool support, this paper presents \mr, a tool for evaluating mutant
reduction techniques in retrospect. Accepting data in a generalised format from a single run of a mutation testing
system, \mr~applies mutant reduction strategies and calculates their efficiency and effectiveness. In addition to being
capable of retrospectively analysing mutant reduction techniques from various domains, \mr~is well-documented and has
been released on GitHub under an open-source license.

% GMK NOTE: I have cut all of this content, using some of it in the new streamlined content

% Databases are utilized pervasively for storing everything from batting and pitching statistics of baseball
% players~\cite{lahmanbaseball} to fingerprints and scars of criminals~\cite{ngi}.  Relational databases are an efficient
% and reliable way to store large amounts of data.  The acceptance of relationships between data entries, as well as
% strict structural constraints upheld by the schema are what make relational databases unique.

% The little work testing the integrity constraints of a schema is not because of a sufficient understanding of the topic.

% database schemas~\footnote{http://goo.gl/eZF1mK}.

% Therefore, ensuring that the schemas that are created are
% also tested is important in upholding the integrity of the data contained within the database.

% The database's schema is the artefact responsible for specifying the data to be stored and how it should be structured
% into tables. A series of integrity constraints is what make the database's schema able to ensure values are unique,
% present, subject to domain-specific conditions and maintain referential integrity~\cite{mcminn2016virtual}.  Although
% the schema is the last line of defence for the data contained within a database, little work has sought to test the
% correctness of the integrity constraints~\cite{mcminn2015effectiveness}.

% Using the tool allows you to study mutant reduction in new domains, so go ahead and introduce databases

As studying the mutant data retrospectively removes the need to comprehend the complexities of a target environment,
mutant reduction methods can be extended to new domains such as that of relational database
schemas~\cite{mcminn2016virtual, mcminn2015effectiveness, wright2013efficient}. Ensuring that a database's schema has
correctly specified integrity constraints is important because these entities ensure that only valid data enters the
database. Even though there are \numquestions~questions about databases on StackExchange, the technical question and
answer website~\cite{stackexchange}, little prior work has focused on testing these integrity
constraints~\cite{mcminn2016virtual}.

% A domain that mutation testing has become more prominent in recently is testing database
% schemas~\cite{mcminn2016virtual, mcminn2015effectiveness, wright2013efficient}. However, due to its computation expense,
% it is not widely adopted in industry to test database schemas.  Although mutation testing is used in a variety of
% domains, the reduction techniques can still be utilized, including retrospective analysis~\cite{jia2011analysis,
%   wong1995reducing, offutt1993experimental, offutt2001mutation}.

% GMK NOTE: I have ultimately added in the reference instead of the footnote

% of database schemas~\cite{stackexchange}. Therefore, ensuring that

Since it is important to assess the quality of tests for relational database schemas, recent work has proposed and
evaluated database-aware mutation analysis techniques~\cite{mcminn2016virtual, mcminn2015effectiveness,
wright2013efficient}. Although the presented method and tool are general, this paper illustrates the retrospective study
of mutant reducers and the use of \mr~in the area of mutation analysis for database schemas. In addition to describing
the implementation of \mr~and overviewing results from applying it to the retrospective study of database schema
mutation, this paper inaugurates the public release of this analysis tool. In summary, the key contributions of this
paper are as follows:

\begin{itemize}

  % Although this is a tool paper, perhaps it is acceptable to claim this ideal as a contribution?

  % \item A tool that supports performing mutant reduction methods retrospectively, a way to quickly identify trade-offs
      % without having to understand the complexities of a mutation testing tool.

  % Make a point about the tool and the features that it provides

  % \item A tool that accepts a generalised input format.
  % \item A tool released as a free and open-source R package.

  \item A tool, called \mr, that

      \begin{itemize}
          \item supports performing mutant reduction methods retrospectively, a way to identify trade-offs
            in efficiency and effectiveness without having to understand the complexities of a mutation testing tool.

          \item accepts a generalised input format, is extendable to various domains, and is released as a free and open-source package in
            the R programming language.

    \end{itemize}

  % The experimental results (even though preliminary) use real-world database schemas

  \item Using database schemas taken from real-world database-centric applications, preliminary results from using
    \mr, highlighting the benefits of mutant reduction and the ease with which these results may be obtained.

\end{itemize}

\input{figures/process}

