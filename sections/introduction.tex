\section{Introduction}
Motivate why a retrospective tool is important. \\
What does this allow for?\\
Why retrospective analysis and not just build reduction techniques into a mutation testing tool?\\

\subsection{Mutation Testing}
don't get too detailed. we can assume readers understand mutation testing

% Mutation testing is a well-known procedure for determining the quality of test
% suites \cite{gopinath2015empirical}. Additionally, as McMinn et al. discovered, the quality of a database schema
% can be determined through the use of mutation testing \cite{mcminn2015effectiveness}. In
% this paper, I am using mutant data from performing mutation analysis on 34 well-known database schemas.
%
% Testing mutations---modified versions of source code containing faults---which is now
% referred to as mutation testing, was originally proposed by Richard A. DeMillo et al.
% in the 1970's \cite{demillo1978hints}. Each modified version of a program or schema contains
% exactly one fault. The goal is to have each modified, or faulty, version of the source code
% fail when executed against the tests \cite{offutt1993experimental}. If a test fails that was expected to fail
% for the given input, then the fault has been exploited and the mutation, also referred to as a mutant,
% was \textit{killed}. A mutant that has been killed is considered to be \textit{dead} and no
% longer needs to remain in the testing process since the faults represented by this type of
% mutant are confirmed as being detectable by the test suite \cite{offutt1993experimental}.
% Conversely, if a test passes, then the fault was not exploited and is considered to remain
% \textit{alive} and are analyzed in further testing \cite{mcminnvirtual}.
%
% After constructing all of the mutants for a given program, the user then adds the test cases
% to a mutation testing system such as \texttt{MAJOR} \cite{just2011major} or
% \texttt{Defects4J} \cite{just2014defects4j}. After adding the tests to a mutation testing system,
% the user then needs to ensure that the output is correct. If the output is incorrect, then
% a fault has been exploited and the mutant is considered to be killed \cite{offutt1993experimental}.
% After all test cases have been executed against all of the live mutants, remaining mutants are either
% considered to be \textit{equivalent} or the test cases are insufficient to kill that type of mutant \cite{gopinath2015empirical}. An equivalent
% mutant always produces the same output as the original program, making it undetectable by any test. On the contrary, a mutant
% is considered to be \textit{normal} if it is not equivalent.
% Finally, a score representing the quality of a test suite or database schema---referred to as the mutation score for the test data---can be calculated.

% \subsection{Calculating Mutation Score}
% Mutation score, displayed in Equation \ref{eq:ms}, is the ratio of killed \textit{normal} faults, denoted $k$ to the total number of \textit{normal} faults \cite{wright2013efficient}.
% The total number of normal mutants can be calculated by summing the number of normal mutants that are both killed and alive, denoted $k$ and $a$, repectively.
% Equivalent mutants are excluded because, by definition, they cannot be detected by a unit test \cite{inozemtseva2014coverage}.
%
% \begin{equation}
%     Mutation \, Score(k,a) = \frac{k}{k+a}
%     \label{eq:ms}
% \end{equation}
%
% Test data with a 100\% mutation score is said to be \textit{mutation adequate} \cite{offutt1993experimental}.
% Mutation adequacy can mean one of two things: the test suite
% or database schema is of high quality or the introduced faults are easily
% discovered and are not stringent predictors of the test suite or schema's quality.

\subsection{The Cost of Mutation Testing}
% As previously noted, mutation testing is not able
% to be used in practice due to its computational expense.
% The primary computational cost is incurred from running the mutated versions
% of the source code or database schema against the test cases or integrity
% constraints \cite{offutt1993experimental}. Due to the fact that each generated
% mutant needs to be run against at least one, possibly many, test cases, mutation
% testing requires a large number of computations \cite{offutt1993experimental}.
%
% There has been a substantial amount of work to find a reduced approach
% for performing mutation testing \cite{gopinath2015empirical, mcminnvirtual, gopinath2015mutation, offutt1993experimental}.
% Offut and Untch categorize the existing mutation testing reduction approaches
% into three categories: do \textit{fewer}, do \textit{smarter} and do \textit{faster} \cite{offutt1993experimental}.
% In this paper, I am only focused on the do fewer categorization,
% specifically, selective mutation testing.

% \begin{figure*}[!ht]
% \centering
% \subfloat[Uniform random sampling]{\includegraphics[width=2.5in]{inventory_perc_v_ms}
% \label{fig:iv_s}}
% \hfil
% \subfloat[Stratified random sampling over mutation operators]{\includegraphics[width=2.5in]{inventory_op_perc_v_ms}
% \label{fig:iv_o}}
% \caption{Comparing uniform random sampling to stratified random sampling over
% mutation operators for the Inventory schema.}
% \label{fig:comp}
% \end{figure*}


\subsection{Mutant Reduction Techniques}
% Mathur suggests an approach to reducing the cost of performing mutation testing by
% reducing the modified or mutant versions of the source code \cite{mathur1991performance}.
% Gopinath et al. discuss two existing approaches for performing selective
% mutation analysis. The two strategies are
% sampling criteria and operator selection \cite{gopinath2015mutation}. Sampling criteria is where I am
% currently focused, specifically on unified random sampling and stratified
% random sampling over mutation operators.
%
% Uniform random sampling is the most trivial sampling approach, proposed by Timothy A. Budd,
% where an arbitrary fraction of the full set of mutants is chosen \cite{budd1980mutation}.
% Zhang et al. analyzed the performance of uniform random sampling as a reduction technique
% and found that sampling as few as 5\% of mutants can be very highly correlated with the full mutation
% score \cite{zhang2010operator, zhang2013operator}.
%
% Wong et al. first suggested sampling the same fraction of mutants from each operator, known as
% stratified random sampling over mutation operators \cite{wong1995reducing}. It is similar
% to uniform random sampling in the way that the same arbitrary fraction is applied. However,
% instead of applying the fraction over all mutants for a schema, the fraction is applied for all operators. In other
% words, the reduced set contains all possible operators, but only a fraction of the mutants
% produced by that operator. Stratified random sampling over mutation operators is subtly different
% from uniform random sampling because each operator is still present in the reduced set, where
% in uniform random sampling this is not considered. For example, an operator that generates few
% mutants compared to an operator that generates many mutants is less likely to have mutants represented
% in the reduced set.
%
% At this point, these are the only reduction strategies present in my research and available for analyzation
% with my tool. As time goes on and I implement more approaches, I will discuss them in further detail.

\subsection{Importance of Testing Database Schemas}
\subsection{Analysing Database Schema Mutants}
refer to the AST2016 paper
still computationally expensive\\
able to utilize existing select approaches

    Key Contributions:
    \begin{itemize}
        \item A tool to study mutant reduction techniques in retrospect.
        \item Released as a free and open-source R package.
        \item Accepts a generalised input format.
    \end{itemize}
