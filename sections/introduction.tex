\section{Introduction}
Programmers make mistakes---often referred to as errors---when writing software
that can be harmful and even result in human fatality \cite{vicente2003programming}.
Running a suite of test cases helps detect many of the errors
that lead to a crash of a program or that cause a logical failure \cite{wagner2005comparing}.
However, simply testing a program is not enough. In order for the results
from a test suite to be substantive, the test suite needs to be of ``high quality''.
Determining the quality of a test suite illustrates how stringently the given
program was tested.

Mutation testing is a widely-recognized technique for determining the quality
of a test suite \cite{gopinath2015mutation}. While there are an immense number
of potential faults for a program, mutation testing primarily focuses on those
which are close to the correct version with the expectation that they will
be representative of all faults \cite{jia2011analysis}.
Of the software testing methods, mutation testing is widely considered the strongest
test criterion in terms of finding the most faults \cite{ammann2008introduction}.

Although mutation testing is the most effective in detecting faults, it possesses
major drawbacks in the computational cost and amount of human interaction required, making it
impractical to use in practice \cite{gopinath2015mutation, wong1995reducing, gopinath2015empirical}.
The major computational cost of mutation testing comes from executing the large number of mutants generated for a
program against a test suite \cite{offutt1993experimental}. Executing a smaller, representative
set of mutants against the test suite has been proposed as a technique to reduce
the cost of mutation testing \cite{jia2011analysis, wong1995reducing, offutt1993experimental, offutt2001mutation}.
This reduction strategy is categorized by Offut and Untuch as a `do fewer' approach \cite{offutt2001mutation}.

There are a number of mutant reduction techniques that can be categorized as do fewer approaches. Two of these techniques are Mutant Sampling and Selective Mutation \cite{jia2011analysis, wong1995reducing, offutt1993experimental}.
Mutant Sampling is the simplest reduction strategy, where a subset---containing a fraction of all mutants---is
chosen randomly \cite{wong1995reducing}. Selective Mutation, also called ``constrained mutation'',
reduces the number of mutants to be analysed by decreasing the operator count \cite{jia2011analysis, offutt1993experimental, mathur1991performance}.
For each of these approaches, a threshold for the maximum number of mutants is set by an arbitrary \(x\%\).

Work has been done in the realm of mutant reduction techniques to find the smallest $x$ that still produces
a representative set of mutant \cite{jia2011analysis, mathur1994empirical}. Most of the work
to minimize representative sets of mutants has been done by integrating an approach into
mutation testing systems and performing mutation testing on each subset of mutants \cite{demillo1988extended, king1991fortran}.

While this way of evaluating reduction techniques is accurate, it is both
expensive to implement and perform due to the number of times mutation testing
needs to be executed on the reduced sets. Retrospectively studying the data
collected from a single run of mutation testing is superior to implementing each
approach into a mutation testing system because it has minimal upfront costs and obviates the need
to understand the complexities of a target environment.

Since studying the data retrospectively removes the need to fathom the complexities of a target environment,
mutation testing can be extended to new domains (e.g., testing database schemas) \cite{mcminn2016virtual, mcminn2015effectiveness, wright2013efficient}.
Testing that a relational database's schema has correctly specified integrity constraints is important
because these restrictions ensure that only valid data enters the database. However, little work has
sought to test these integrity constraints \cite{mcminn2016virtual}.

Databases are utilized pervasively for storing everything from batting and pitching statistics of baseball
players \cite{lahmanbaseball} to fingerprints, scars and tattoos of criminals \cite{ngi}.
Although enterprise use of non-relational, or ``NoSQL'', databases is becoming more common,
relational databases endure ubiquitously.
Relational databases are an efficient and reliable way to store large amounts of data.
The acceptance of relationships between data entries, as well as strict structural constraints
upheld by the schema are what make relational databases unique.

The database's schema is the artifact responsible for specifying the data to be stored and
how it should be structured into tables. A series of integrity constraints
are what make the database's schema able to ensure values are unique, present,
subject to domain-specific conditions and maintain referential integrity \cite{mcminn2016virtual}.
Although the schema is the last line of defence for the data contained
within a database, little work has sought to test the correctness of the integrity constraints \cite{mcminn2015effectiveness}.

\input{figures/process}

The small amount of work testing the integrity constraints of a database's schema is not
because of a sufficient understanding of the topic. The 941,910 questions posted on
the technical question and answer website, StackExchange, indicate the demand for support
of database schemas.\footnote{http://goo.gl/eZF1mK} Therefore, ensuring that
the schemas that are created are also tested is important in upholding the integrity
of the data contained within the database.

Mutation testing is versatile and can be used for detecting errors made by programmers in many domains.
A domain that mutation testing has been more frequently utilized in recently is testing database
schemas \cite{mcminn2016virtual, mcminn2015effectiveness, wright2013efficient}. However,
again, due to its computation expense, it is not widely adopted in industry. Since we
are able to use mutation testing, we can take advantage of the many
existing reduction approaches \cite{jia2011analysis, wong1995reducing, offutt1993experimental, offutt2001mutation}
as well as this new notion of retrospective analysis.

Retrospective analysis is substantially cheaper than applying an
individual reduction strategy to mutation testing and then evaluating that
approach. This is the case because the expense of mutation testing in
retrospective analysis is incurred only once, rather than for
every reduction technique. Analysing the effectiveness of an approach in a reflective fashion
is possible because we collect all of the data necessary from
the single execution of mutation testing. We introduce the
first and only tool that analyses reduction techniques retrospectively
in \mr.

\mr is a tool for evaluating the effectiveness of mutation analysis reduction techniques
in retrospect. Using data in a generalised format from a single execution of mutation testing, \mr
employs each reduction strategy and performs calculations to determine the
effectiveness. By accepting a generalised input format, \mr is capable of
retrospectively analysing mutant reduction techniques from various domains.
Additionally, \mr is modifiable, well-documented and has been released on
GitHub under and open-source license.

    In summary, the key contributions of this work are as follows:
    \begin{itemize}
        \item A tool to study mutant reduction techniques in retrospect.
        \item A tool that accepts a generalised input format.
        \item A tool released as a free and open-source R package.
    \end{itemize}
