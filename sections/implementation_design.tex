\subsection{Tool Design}

The \mr tool accepts a generalised input format which enables it to be used to retrospectively analyse mutation testing
data from programs and also emerging domains, such as databases. Although the domain under test may differ,
similar data can be collected (e.g., mutation operators, mutant killed statuses, type of mutant). While more data
can optionally be collected from mutation testing, the additional data is more
dependent on the domain. Sample data collected from performing mutation testing on database schemas
is included in Table \ref{tbl:study-data} where the additional data are
the unique identifier for the configuration of DBMS and schema (Indentifier),
the database management system under test (DBMS), the database schema (Schema) and the creation time of a mutant (Time).

Additionally, in our experiments, we chose to analyse a select number of schemas, shown in Table \ref{tbl:study-schemas}.
We chose these nine schemas because they range in triviality. For example, the MozillaPermissions schema contains
a single constraint, where as the JWhoisServer has a total of 50 constraints. This allowed us to evaluate the effectiveness
of the \mr tool for schemas of varying complexities.

The \mr tool was designed to empirically study the effectiveness of
various reduction techniques in retrospect. The two reduction techniques mentioned earlier which are often considered
to be the most utilized are uniform random sampling
and sampling over operators which both require an arbitrary percentage, $x$, to be chosen as the maximum threshold
for the number of mutants to be analysed from a set. The structure of the experiment function for the two
reduction techniques is displayed in Figure \ref{fig:experiment-structure}.

Where Wong and Mathur in their studies \cite{mathur1994empirical}, \cite{wong1993mutation} conducted
experiments using mutant sampling with $x$ from $10\%$ to $40\%$ increasing by steps of $5\%$, we
chose to analyse $x$ at $1\%$ and then increase by $10\%$ intervals up to $90\%$. By lowering
the granularity of the experiment to $10\%$ intervals instead of
$1\%$ or $5\%$, we are able to reduce the cost of performing the retrospective analysis while observing
similar trends.

When determining the number of trials necessary, we followed
the recommendations of Traeger et al. and Arcuri, by running 30 trials for each configuration of a reduction approach \cite{traeger2008nine, arcuri2014hitchhiker}.
The general rule in many fields of science is to at least perform at least 30 observations to show with high confidence
that the obtained results are statistically significant and to allow for the results to approximate a normal
distribution.
