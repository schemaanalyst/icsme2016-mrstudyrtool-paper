\input{figures/mrstudyr}

\section{\textit{mrstudyr}: Mutant Reduction Studier}

Performing the entire mutation analysis process, displayed in Figure \ref{fig:process},
is both expensive in terms of time and computational requirements. The mutation testing
phase, displayed in Figure \ref{fig:process}, of the mutation analysis
process consists of generating and executing the mutants. The primary
expense of the mutation analysis process is incurred in the mutation testing phase
due to the large number of mutants generated---even for programs with few lines of code \cite{offutt2001mutation}.

The next phase in the mutation analysis process is retrospective analysis. In this
phase, mutants are found to either be dead or alive. Where a mutant is considered
``dead''---or to have been killed---if when executing the modified version of the source
code the output differed from the original version. Conversely, a mutant remains alive
if the output from the modified version of the source code does not differ from the
original version. More importantly, in this phase of the mutation analysis process,
we are able to evaluate the effectiveness of various reduction techniques.

By retrospectively analysing each reduction technique's effectiveness, we are
able to avoid the cost of performing mutation testing more than once. To alleviate
the additional executions, data needs to be collected
from the first run. Displayed in Figure \ref{fig:mrstudyr},
the \mr tool uses the data collected from mutation testing to conduct further analyses
regarding the effectiveness of a reduction technique.

The data, at the very least, needs to include the status of
a mutant after testing (e.g., dead or alive), the type of mutant (e.g., normal, duplicate, equivalent, or stillborn)
and the mutation operators used. In addition to the minimum requirements, the data can include much
more detail about the mutants. An example of additional data that may be collected are the database
management system or schema under test and the cost of generating each mutant.

As indicated previously, the \mr tool requires the status of a mutant after testing to be included
in the data provided.
Based on the number of dead and alive mutants after mutation testing,
the \mr tool calculates and associates a mutation score with a set of mutants.
The mutation score associated with a mutant set is a value representative of how well
the test suite is at identifying and killing mutants in that set. The \mr tool first calculates the
mutation score for the non-reduced set of mutants and then later for each reduced set. The mutation
score for the non-reduced set of mutants is used as a baseline for determining
how well each reduction technique performs.

In order to calculate the effectiveness of a reduction technique, the technique
must first be exercised on the data collected from mutation testing. The \mr tool
performs the reduction techniques and returns the new, reduced mutant data,
displayed in Figure \ref{fig:mrstudyr}. The effectiveness---how well a reduced set is able to represent
the non-reduced set---of a reduction technique is then evaluated
based on five metrics: mutation score, the correlation of the reduced and non-reduced sets' mutation scores,
the scale of creation-cost reduction and the mean absolute and root mean squared error.

These five evaluation metrics help determine how representative each reduced
set is of the non-reduced set of mutants. Mutation score is calculated
by dividing the number of killed mutants over the total number of normal---not
equivalent, duplicate or stillborn---mutants. Then, as provided by the ``Kendal'' R package,
we use Kendall's $\tau_b$ correlation coefficient---because of its tie-awareness---to
determine the correlation value between mutation scores of the non-reduced and reduced sets \cite{mcleod2005kendall}.

Kendall's $\tau_b$ returns a measurement of correlation between -1 and 1, meaning that
there is a strong negative or positive correlation between two sets, respectively. A value
of 0 means that there is no correlation between the sets. Additionally, we adopt the
Guildford scale to describe correlation values between sets, with the absolute value
of a coefficient being described as ``low'', ``moderate'', ``high'' or ``very high'' when
it is less than 0.4, between 0.4 and 0.7, ranging from 0.7 to 0.9 or 0.9 and above, respectively \cite{inozemtseva2014coverage}.

Next, a value representing the magnitude of diminution in the cost of creating the mutants between the non-reduced
and reduced set is calculated. This value is calculated by subtracting
the cost of creating the reduced set from the cost of creating all mutants. Then
dividing that value by the cost of creating all mutants. This helps
determine whether it is worth performing a reduction technique---even if the
reduced set has a very highly correlated mutation score with the non-reduced set.

Finally, we chose to calculate both mean absolute (MAE) and root mean squared errors (RMSE) giving equal weight to
all errors and extra weight to larger errors, respectively. This provides
us with the ability to see the deviation between the mutation score of the reduced and
non-reduced set for a given reduction technique. By using both MAE and RMSE,
we are able to calculate the error for the mutation score of the reduced sets
where MAE provides a high-level error RMSE emphasises large errors.

As noted with the ``Kendall'' R package and is also true for the ``Metric'' R Package, which
encompasses both MAE and RMSE calculations. Both packages are freely available and easily adopted being
that they have been released as a standardised R packages.

The R programming language for statistical data analysis was specifically designed to
be a full statistical language for conducting empirical studies. Following its predecessor, the S programming
language, R is a powerful means for data analysts to express computations \cite{ihaka1996r}.
Additionally, in R, the fundamental way to share code is via a package.

An R package includes code, data, documentation, tests and are easy to distribute \cite{wickham2015r}.
For example, installing the \mr tool requires a mere three commands in the R console---assuming R installed on the host machine.
First, \texttt{install.packages("devtools")}, then \texttt{library(devtools)} to install and load the \texttt{devtools}\footnote{https://goo.gl/Je5EO2} package, respectively.
The \texttt{devtools} package provides a framework for easily creating a package and maintaining it throughout the development process.
Finally, to obtain the \mr\footnote{https://github.com/mccurdyc/mrstudyr} tool, use the \texttt{devtools} package to install it
from the popular Git repository hosting service, GitHub\footnote{https://github.com/}, using the following command \texttt{devtools::install\_github("mccurdyc/mrstudyr")}.
In addition to being easy to install, the \mr tool accepts a generalised input format.

Accepting a generalised input format allows the \mr tool to be used to retrospectively analyse mutation testing
data from familiar and also emerging domains, such as databases. Although mutation
testing can be utilized in various domains, similar data can be collected from any
domain (e.g., mutation operators, mutant statuses, type of mutant). While more data
can optionally be collected from mutation testing, the additional data is more
dependent on the domain being under observation.
